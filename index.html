---
layout: page
slide_id: 0
---




<div>
        
        <h3>MUWS Workshop 2022</h3>

            <p> The 1st International Workshop on Multimodal Understanding for the Web and Social Media (MUWS), co-located with 
                <a href="https://www2022.thewebconf.org/"> The WebConf (WWW) 2022</a></p>

            <p><b>Participation</b>: Online </p>

            <p><b>Registration page: </b><a href="https://www2022.thewebconf.org/registration/">https://www2022.thewebconf.org/registration/</a> </p>

            <p><b>Workshop date</b>: April 26, 2022</p>

            <p><b>Schedule (Central European Summer Time)</b></p>

            <p><b>14:00 - 14:05</b> - Welcome session </p>
            <p><b>14:05 - 14:50</b> - Keynote talk by <a href="https://www.cs.is.i.nagoya-u.ac.jp/people/ichiro-ide/"><b>Ichiro Ide</b></a> "Tailoring Applications to Users Through Multi-modal Understanding" </p>

                <div>
                <p style="float: left;"><img src="./assets/images/2022_images/ide.jpg" style="max-width:75%;"></p>
                <p style="max-width:100%;">Prof. Ichiro Ide received his BEng, MEng, and PhD from The University of Tokyo in 1994, 1996, and 2000, respectively. He became an Assistant Professor at the National Institute of Informatics, Japan in 2000. Since 2004, he has been an Associate Professor, and since 2020, a Professor at Nagoya University. His research interest ranges from the analysis and indexing to retargeting of multimedia contents, especially in large-scale broadcast video archives, mostly on news, cooking, and sports contents.</p>
                </div>

            <p></p>
            <p><b>14:50 - 15:15</b> - Invited talk by <a href="https://www.chiaoitseng.de/"><b>Chiao-I Tseng</b></a> "Multimodal Discourse Approach to Narrative Strategies of Online News Videos"</p>
            <div>
                <p style="float: left;"><img src="./assets/images/2022_images/tseng.webp" style="max-width:75%;"></p>
                <p style="max-width:100%;"> Dr. Chiao-I Tseng is a multimodal linguist and senior researcher in the Faculty of Linguistics and Literary Sciences at the University of Bremen. She completed my PhD in Applied Linguistics at the University of Bremen in 2010. She specialises in developing discourse methods for analysing visual and audiovisual text structures and contents, particularly the methods for multimodal cohesion and coherence, events actions, narrative time and space. </p>
            </div>

            
            </br>
            </br>

            <p><b>15:15 - 15:30</b> - <b>Mesut Erhan Unal</b>, Adriana Kovashka, Wen-Ting Chung and Yu-Ru Lin "Visual Persuasion in COVID-19 Social Media Content: A Multi-Modal Characterization"

            <p><b>15:30 - 15:45</b> - Break </p>

            <p><b>15:45 - 16:05</b> - Invited talk by  <a href="https://www.tib.eu/en/research-development/research-groups-and-labs/visual-analytics/staff/christian-otto"><b>Christian Otto</b></a> "Characterization and Classification of Semantic Image-Text Relations" </p>

            <div>
                <p style="float: left;"><img src="./assets/images/2022_images/otto.jpg" style="max-width:75%;"></p>
                <p style="max-width:100%;"> Christian Otto is a doctoral researcher working at Visual Analytics Group, TIB. His research topic is the examination of cross-modal interrelations between visual and textual information. This includes the consideration of insights from communication sciences, the research design of deep learning applications to analyse multimodal information and the incorporation of this knowledge into search engines, such as for scientific publications or scientific videos.</p>
            </div>

            </br>
            </br>

            <p><b>16:05 - 16:20</b> -  <b>Shivangi Singhal</b>, Tanisha Pandey, Saksham Mrig, Rajiv Ratn Shah and Ponnurangam Kumaraguru "Leveraging Intra and Inter Modality Relationship for Multimodal Fake News Detection"</p>
            <p><b>16:20 - 16:35</b> - <b>Kohei Uehara</b>, Yusuke Mori, Yusuke Mukuta and Tatsuya Harada "ViNTER: Image Narrative Generation with Emotion-Arc-Aware Transformer"</p>
            <p><b>16:35 - 16:50</b> - <b>Diego Garcia-Olano</b>, Yasumasa Onoe and Joydeep Ghosh "Improving and Diagnosing Knowledge-Based Visual Question Answering via Entity Enhanced Knowledge Injection"</p>

            <p><b>16:50 - 17:00</b> - Closing session</p>


            <p class="text-center"> 
                <a href="https://www2022.thewebconf.org"> <img alt="WWW 2022" src="./assets/images/logo_www_2022.png" height="150px"></a>
            </p>

            <p class="text-center">
                <img alt="twitter" src="./assets/images/twitter_logo.png" height="60px"><a href="https://twitter.com/MuwsWorkshop">Follow us on Twitter</a>
            </p>
    
</div>


<!-- div class="row">
    <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 col-xl-6 text-justify conference-text">

            <h5>MUWS Workshop 2022</h5>

            <p> The 1st International Workshop on Multimodal Understanding for the Web and Social Media (MUWS) will be co-located with 
                <a href="https://www2022.thewebconf.org/"> The WebConf (WWW) 2022</a>, April 25-29 2022.</p> -->


            <!-- <p> The goal of the interdisciplinary MUWS Workshop is to bring together researchers and practitioners from the fields of Information Retrieval, Natural Language Processing, Computer Vision, Human Computation, and Semiotics to discuss and evaluate methods and solutions for effective and efficient analytics of multimodal information present in the Web or social media.

            We are interested in approaches, tasks, and metrics for effectively analysing multimedia information such as image-text pairs and videos to design methodologies that jointly consider information from multiple modalities. The interdisciplinary nature of processing such multimodal data involves combining ideas and methods from the fields mentioned above. We envision the workshop as a forum for researchers and practitioners from academia and industry for original contributions and practical application on multimodal information processing, mining, retrieval, search, and management.</p>

                <p>The topics of interest include, but are by no means limited
                to:</p>
                
                <ul>
                <li>Multimodal Event Detection, and Understanding</li>
                <li>Multimodal News Analytics</li>
                <li>Multimodal Sentiment Analysis</li>
                <li>Multimodal Emotion Recognition</li>
                <li>Multimodal Sarcasm Detection</li>
                <li>Multimodal Hate Speech Detection</li>
                <li>Misinformation Detection for Multimodal Data</li>
                <li>Unsupervised, Self-supervised, or Semi-supervised Learning for Multimodal Data</li>
                <li>Multimodal Question Answering Systems</li>
                <li>Image-text Relations, Cross-modal Relations</li>
                <li>Semantic Relations (semiotics)</li>
                <li>Multimodal Rhetoric in Online Media</li>
                </ul>


   
                {% include contact-us.html %}

    </div> -->
    <!-- <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 col-xl-6"> -->
            <!-- {% include card-important-dates.html %} -->
            <!-- {% include card-news.html %} -->
            <!-- {% include conference-badge.html %} -->
            <!-- {% include twitter-badge.html %} -->
    <!-- </div> -->
<!-- </div> -->
