---
layout: page
slide_id: 0
---




<div class="row">
    <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 col-xl-6 text-justify conference-text">

            <h5>MUWS Workshop 2022</h5>

            <p> The 1st International Workshop on Multimodal Understanding for the Web and Social Media (MUWS) will be co-located with 
                <a href="https://www2022.thewebconf.org/"> The WebConf (WWW) 2022</a>, April 25-29 2022.</p>


            <p><b>Workshop date and time</b>: April 26, 2022, afternoon (CET)</p>

            <p><b>Participation</b>: Online </p>
            <p><b>Registration page:</b><a href="https://www2022.thewebconf.org/registration/">https://www2022.thewebconf.org/registration/</a> </p>

            <p>14:00 - 14:05 - Introduction of the workshop </p>
            <p>14:05 - 14:50 - Keynote talk by <a href="https://www.cs.is.i.nagoya-u.ac.jp/people/ichiro-ide/">Ichiro Ide</a> "Tailoring Applications to Users Through Multi-modal Understanding"
            <p>14:50 - 15:15 - Invited talk by <a href="https://www.chiaoitseng.de/">Chiao-I Tseng</a> "Multimodal Discourse Approach to Narrative Strategies of Online News Videos" - Chiao-I Tseng </p>
            <p>15:15 - 15:30 - Paper presentation by Mesut Erhan Unal "Visual Persuasion in COVID-19 Social Media Content: A Multi-Modal Characterization"

            <p>15:30 - 15:45 - Break </p>

            <p>15:45 - 16:05 - Invited Talk by  <a href="https://www.tib.eu/en/research-development/research-groups-and-labs/visual-analytics/staff/christian-otto">Christian Otto</a> "Characterization and Classification of Semantic Image-Text Relations" </p>
            <p>16:05 - 16:20 - Paper presentation by Shivangi Singhal "Leveraging Intra and Inter Modality Relationship for Multimodal Fake News Detection"</p>
            <p>16:20 - 16:35 - Paper presentation by Kohei Uehara "ViNTER: Image Narrative Generation with Emotion-Arc-Aware Transformer"</p>
            <p>16:35 - 16:50 - Paper presentation by Diego Garcia-Olano "Improving and Diagnosing Knowledge-Based Visual Question Answering via Entity Enhanced Knowledge Injection"</p>

            <p>16:50 - Wrap up session (5 mins)</p>


            <p class="text-center"> 
                <a href="https://www2022.thewebconf.org"> <img alt="WWW 2022" src="./assets/images/logo_www_2022.png" height="150px"></a>
            </p>

            <p class="text-center">
                <img alt="twitter" src="./assets/images/twitter_logo.png" height="60px"><a href="https://twitter.com/MuwsWorkshop">Follow us on Twitter</a>
            </p>


            <!-- <p> The goal of the interdisciplinary MUWS Workshop is to bring together researchers and practitioners from the fields of Information Retrieval, Natural Language Processing, Computer Vision, Human Computation, and Semiotics to discuss and evaluate methods and solutions for effective and efficient analytics of multimodal information present in the Web or social media.

            We are interested in approaches, tasks, and metrics for effectively analysing multimedia information such as image-text pairs and videos to design methodologies that jointly consider information from multiple modalities. The interdisciplinary nature of processing such multimodal data involves combining ideas and methods from the fields mentioned above. We envision the workshop as a forum for researchers and practitioners from academia and industry for original contributions and practical application on multimodal information processing, mining, retrieval, search, and management.</p>

                <p>The topics of interest include, but are by no means limited
                to:</p>
                
                <ul>
                <li>Multimodal Event Detection, and Understanding</li>
                <li>Multimodal News Analytics</li>
                <li>Multimodal Sentiment Analysis</li>
                <li>Multimodal Emotion Recognition</li>
                <li>Multimodal Sarcasm Detection</li>
                <li>Multimodal Hate Speech Detection</li>
                <li>Misinformation Detection for Multimodal Data</li>
                <li>Unsupervised, Self-supervised, or Semi-supervised Learning for Multimodal Data</li>
                <li>Multimodal Question Answering Systems</li>
                <li>Image-text Relations, Cross-modal Relations</li>
                <li>Semantic Relations (semiotics)</li>
                <li>Multimodal Rhetoric in Online Media</li>
                </ul>


   
                {% include contact-us.html %}

    </div> -->
    <!-- <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 col-xl-6"> -->
            <!--######### important dates ##########-->
            {% include card-important-dates.html %}
            <!--####################################-->
            <!--######### news #####################-->
            {% include card-news.html %}
            <!--####################################-->
            {% include conference-badge.html %}
            <!--####################################-->
            {% include twitter-badge.html %}
            <!--####################################-->
    <!-- </div> -->
</div>
